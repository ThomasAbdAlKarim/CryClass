{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "9ddfba760c93d0781cb88c4db9a31eb68ca4e1616821530f19d735f356a5c9ec"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import Loader\n",
    "import numpy as np\n",
    "import librosa.display\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Trim(Signal,Sr,Len = 5):\n",
    "    Signal = np.array(Signal[:(Len*Sr)])\n",
    "    return Signal\n",
    "    \n",
    "\n",
    "def Pad(Signal,Len,Sr = 22050):\n",
    "    if len(Signal) < (Len*Sr):\n",
    "        Pad_Size = (Len*Sr)-len(Signal)\n",
    "        Padded = np.pad(Signal, (0,Pad_Size ), 'constant')\n",
    "        return Padded\n",
    "    return Signal\n",
    "\n",
    "def Waveform(Signal,Sr):\n",
    "    librosa.display.waveplot(Signal,sr=Sr)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def FFT(Signal,Sr):\n",
    "    fft = np.fft.fft(Signal)\n",
    "    magnitude = np.abs(fft)\n",
    "    freq = np.linspace(0,Sr,len(magnitude))\n",
    "    freq = freq[:int(len(freq)/2)]\n",
    "    magnitude = magnitude[:int(len(magnitude)/2)]\n",
    "    plt.plot(freq,magnitude)\n",
    "    plt.xlabel(\"Frequency\")\n",
    "    plt.ylabel(\"Magnitude\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def Sepctogram(Signal,Sr,Mode = 'Normal'): #Using STFT\n",
    "    Sample_Num = 2048 #Per fft\n",
    "    Hop_length = 512 \n",
    "    stft = librosa.core.stft(Signal,hop_length=Hop_length,n_fft=Sample_Num)\n",
    "    spect = np.abs(stft)\n",
    "    if Mode == 'log':\n",
    "        spect = librosa.amplitude_to_db(spect)\n",
    "    librosa.display.specshow(spect,sr=Sr,hop_length = Hop_length)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "def MFCC(Signal,Sr):\n",
    "    Sample_Num = 2048 #Per fft\n",
    "    Hop_length = 512 \n",
    "    MFCC = librosa.feature.mfcc(Signal,sr=Sr,n_fft=Sample_Num,hop_length = Hop_length,n_mfcc=20)\n",
    "    librosa.display.specshow(MFCC,sr=Sr,hop_length = Hop_length)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"MFCC\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "def Save_MFCC(Signal,Sr,n_mfcc=13,n_fft=2048,hop_length=512):\n",
    "    MFCC = librosa.feature.mfcc(Signal,sr=Sr,n_fft=n_fft,hop_length = hop_length,n_mfcc=n_mfcc)\n",
    "    return MFCC/303.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Audio Loaded\n"
     ]
    }
   ],
   "source": [
    "Pain_Path,Hungry_Path,Uncomfortable_Path = Loader.LOAD()\n",
    "Audio_Hungry = []\n",
    "Audio_Pain = []\n",
    "Audio_UnCom = []\n",
    "for path in Hungry_Path:\n",
    "    Signal,Sr = librosa.load(path,sr=22050) #len(Signal) = sr * AudioTime  \n",
    "    Audio_Hungry.append(Trim(Pad(Signal,5,Sr),Sr))\n",
    "\n",
    "for path in Pain_Path:\n",
    "    Signal,Sr = librosa.load(path,sr=22050) #len(Signal) = sr * AudioTime  \n",
    "    Audio_Pain.append(Trim(Pad(Signal,5,Sr),Sr))\n",
    "\n",
    "for path in Uncomfortable_Path:\n",
    "    Signal,Sr = librosa.load(path,sr=22050) #len(Signal) = sr * AudioTime  \n",
    "    Audio_UnCom.append(Trim(Pad(Signal,5,Sr),Sr))\n",
    "\n",
    "print('Audio Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(Audio_Pain)\n",
    "np.random.shuffle(Audio_UnCom)\n",
    "np.random.shuffle(Audio_Hungry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = []\n",
    "Y = []\n",
    "\n",
    "for i in range(len(Audio_UnCom) + 100):\n",
    "    Data.append(Save_MFCC(Audio_Hungry[i],Sr))\n",
    "    Y.append(0)\n",
    "\n",
    "for Audio_File in Audio_Pain:\n",
    "    Data.append(Save_MFCC(Audio_File,Sr))\n",
    "    Y.append(1)\n",
    "\n",
    "for Audio_File in Audio_UnCom:\n",
    "    Data.append(Save_MFCC(Audio_File,Sr))\n",
    "    Y.append(2)\n",
    "\n",
    "Data = np.array(Data)\n",
    "Y = np.array(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Split = int(len(Data)*0.90)\n",
    "X_Train = Data[:Split]\n",
    "Y_Train = Y[:Split]\n",
    "X_Test = Data[Split:]\n",
    "Y_Test = Y[Split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/25\n",
      "83/83 [==============================] - 1s 13ms/step - loss: 0.9509 - accuracy: 0.5932 - val_loss: 1.5412 - val_accuracy: 0.2909\n",
      "Epoch 2/25\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.7769 - accuracy: 0.7410 - val_loss: 1.3064 - val_accuracy: 0.3818\n",
      "Epoch 3/25\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.7274 - accuracy: 0.7101 - val_loss: 0.7326 - val_accuracy: 0.5273\n",
      "Epoch 4/25\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.7106 - accuracy: 0.7410 - val_loss: 2.0311 - val_accuracy: 0.0909\n",
      "Epoch 5/25\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.6522 - accuracy: 0.7521 - val_loss: 1.1924 - val_accuracy: 0.4545\n",
      "Epoch 6/25\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.7962 - val_loss: 1.4097 - val_accuracy: 0.5636\n",
      "Epoch 7/25\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5514 - accuracy: 0.8086 - val_loss: 0.9892 - val_accuracy: 0.6182\n",
      "Epoch 8/25\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7861 - val_loss: 1.0715 - val_accuracy: 0.6000\n",
      "Epoch 9/25\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8734 - val_loss: 1.6043 - val_accuracy: 0.4545\n",
      "Epoch 10/25\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.3956 - accuracy: 0.8524 - val_loss: 1.3322 - val_accuracy: 0.5818\n",
      "Epoch 11/25\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3406 - accuracy: 0.8796 - val_loss: 0.9347 - val_accuracy: 0.5636\n",
      "Epoch 12/25\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3162 - accuracy: 0.9049 - val_loss: 1.4573 - val_accuracy: 0.5273\n",
      "Epoch 13/25\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.3166 - accuracy: 0.8879 - val_loss: 0.8914 - val_accuracy: 0.7818\n",
      "Epoch 14/25\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2934 - accuracy: 0.8908 - val_loss: 1.4490 - val_accuracy: 0.6364\n",
      "Epoch 15/25\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2851 - accuracy: 0.9039 - val_loss: 1.2805 - val_accuracy: 0.6000\n",
      "Epoch 16/25\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2286 - accuracy: 0.9234 - val_loss: 1.2641 - val_accuracy: 0.5818\n",
      "Epoch 17/25\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.2095 - accuracy: 0.9223 - val_loss: 1.2832 - val_accuracy: 0.7091\n",
      "Epoch 18/25\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1291 - accuracy: 0.9663 - val_loss: 0.9663 - val_accuracy: 0.6909\n",
      "Epoch 19/25\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1418 - accuracy: 0.9407 - val_loss: 1.3317 - val_accuracy: 0.6000\n",
      "Epoch 20/25\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1391 - accuracy: 0.9538 - val_loss: 0.9453 - val_accuracy: 0.7273\n",
      "Epoch 21/25\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1775 - accuracy: 0.9423 - val_loss: 0.8444 - val_accuracy: 0.7636\n",
      "Epoch 22/25\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0852 - accuracy: 0.9731 - val_loss: 0.6519 - val_accuracy: 0.8000\n",
      "Epoch 23/25\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.1141 - accuracy: 0.9682 - val_loss: 1.0661 - val_accuracy: 0.7636\n",
      "Epoch 24/25\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0953 - accuracy: 0.9542 - val_loss: 1.5480 - val_accuracy: 0.6364\n",
      "Epoch 25/25\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 0.0812 - accuracy: 0.9579 - val_loss: 1.1984 - val_accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "Model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv1D(20,5,activation='relu',padding='same',input_shape = (13,216)),\n",
    "        tf.keras.layers.MaxPool1D(2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512,activation= 'relu'),\n",
    "    tf.keras.layers.Dense(256,activation= tf.keras.activations.elu),\n",
    "    tf.keras.layers.Dense(128,activation='relu'),   \n",
    "    tf.keras.layers.Dense(3,activation='softmax')\n",
    "])\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "Model.compile(optimizer=optimizer,loss=\"sparse_categorical_crossentropy\",metrics = [\"accuracy\"])\n",
    "Hist = Model.fit(X_Train,Y_Train,epochs=25,batch_size=6,validation_data=(X_Test,Y_Test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv1d (Conv1D)              (None, 13, 20)            21620     \n_________________________________________________________________\nmax_pooling1d (MaxPooling1D) (None, 6, 20)             0         \n_________________________________________________________________\nflatten (Flatten)            (None, 120)               0         \n_________________________________________________________________\ndense (Dense)                (None, 512)               61952     \n_________________________________________________________________\ndense_1 (Dense)              (None, 256)               131328    \n_________________________________________________________________\ndense_2 (Dense)              (None, 128)               32896     \n_________________________________________________________________\ndense_3 (Dense)              (None, 3)                 387       \n=================================================================\nTotal params: 248,183\nTrainable params: 248,183\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Name = input('Name: ')\n",
    "Model.save(Name + '.h5')\n"
   ]
  }
 ]
}